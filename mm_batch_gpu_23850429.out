Testing mkn_offload with size 100...
tee: /dev/tty: No such device or address
Saved: mkn_offload, 100, 0.001626, 1.230012
Testing mkn_offload with size 200...
tee: /dev/tty: No such device or address
Saved: mkn_offload, 200, 0.004125, 3.878787
Testing mkn_offload with size 500...
tee: /dev/tty: No such device or address
Saved: mkn_offload, 500, 0.002566, 97.427903
Testing mkn_offload with size 1000...
tee: /dev/tty: No such device or address
Saved: mkn_offload, 1000, 0.009839, 203.272690
Testing mkn_offload with size 2000...
tee: /dev/tty: No such device or address
Saved: mkn_offload, 2000, 0.089483, 178.804912
Testing mkn_offload with size 5000...
tee: /dev/tty: No such device or address
Saved: mkn_offload, 5000, 1.064970, 234.748396
Testing mnk_offload with size 100...
tee: /dev/tty: No such device or address
Saved: mnk_offload, 100, 0.003462, .577700
Testing mnk_offload with size 200...
tee: /dev/tty: No such device or address
Saved: mnk_offload, 200, 0.002050, 7.804878
Testing mnk_offload with size 500...
tee: /dev/tty: No such device or address
Saved: mnk_offload, 500, 0.001891, 132.205182
Testing mnk_offload with size 1000...
tee: /dev/tty: No such device or address
Saved: mnk_offload, 1000, 0.003277, 610.314311
Testing mnk_offload with size 2000...
tee: /dev/tty: No such device or address
Saved: mnk_offload, 2000, 0.016868, 948.541617
Testing mnk_offload with size 5000...
tee: /dev/tty: No such device or address
Saved: mnk_offload, 5000, 0.319038, 783.605714
Testing blk_offload with size 100...
tee: /dev/tty: No such device or address
Saved: blk_offload, 100, 0.001610, 1.242236
Testing blk_offload with size 200...
tee: /dev/tty: No such device or address
Saved: blk_offload, 200, 0.004272, 3.745318
Testing blk_offload with size 500...
tee: /dev/tty: No such device or address
Saved: blk_offload, 500, 0.001788, 139.821029
Testing blk_offload with size 1000...
tee: /dev/tty: No such device or address
Saved: blk_offload, 1000, 0.002576, 776.397515
Testing blk_offload with size 2000...
tee: /dev/tty: No such device or address
Saved: blk_offload, 2000, 0.009400, 1702.127659
Testing blk_offload with size 5000...
tee: /dev/tty: No such device or address
Saved: blk_offload, 5000, 0.134146, 1863.641107
Testing asy_offload with size 100...
tee: /dev/tty: No such device or address
Saved: asy_offload, 100, 0.016317, .122571
Testing asy_offload with size 200...
tee: /dev/tty: No such device or address
Saved: asy_offload, 200, 0.004529, 3.532788
Testing asy_offload with size 500...
tee: /dev/tty: No such device or address
Saved: asy_offload, 500, 0.002127, 117.536436
Testing asy_offload with size 1000...
tee: /dev/tty: No such device or address
Saved: asy_offload, 1000, 0.004329, 462.000462
Testing asy_offload with size 2000...
tee: /dev/tty: No such device or address
Saved: asy_offload, 2000, 0.018481, 865.754017
Testing asy_offload with size 5000...
tee: /dev/tty: No such device or address
Saved: asy_offload, 5000, 0.330286, 756.919760
Results saved to offload_performance_results_gflops_size2.csv

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 23850429: <mm_batch_gpu> in cluster <dcc> Done

Job <mm_batch_gpu> was submitted from host <n-62-12-81> by user <s230274> in cluster <dcc> at Thu Jan 23 20:48:10 2025
Job was executed on host(s) <32*n-62-12-89>, in queue <hpcintrogpu>, as user <s230274> in cluster <dcc> at Thu Jan 23 20:48:11 2025
</zhome/97/2/198344> was used as the home directory.
</zhome/97/2/198344/assignment_3/hpc_assignment3> was used as the working directory.
Started at Thu Jan 23 20:48:11 2025
Terminated at Thu Jan 23 20:50:39 2025
Results reported at Thu Jan 23 20:50:39 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# Batch script to test all offload methods and compute GFLOPS/s
# Batch script for profiling all matrix multiplication implementations using NSight Systems (NSYS) and Nsight Compute (NCU)

#BSUB -J mm_batch_gpu
#BSUB -o mm_batch_gpu_%J.out
#BSUB -q hpcintrogpu
#BSUB -n 32
#BSUB -R "rusage[mem=2048]"
#BSUB -W 15
#BSUB -R "span[hosts=1]"
#BSUB -gpu "num=1:mode=exclusive_process"

# Define method names
METHODS="mkn_offload mnk_offload blk_offload asy_offload"

# Define matrix sizes
SIZES="100 200 500 1000 2000 5000"

# Output file
RESULTS_FILE="offload_performance_results_gflops_size2.csv"

# Clear old results
echo "Method, Size, Kernel (s), GFLOPS/s" > $RESULTS_FILE

# Load necessary modules (adjust if required)
module load nvhpc/24.11

# Run tests for each method and size
for METHOD in $METHODS; do
    for SIZE in $SIZES; do
        echo "Testing $METHOD with size $SIZE..."

        # Run executable and capture output
        OUTPUT=$(./matmult_c.nvc++ "$METHOD" "$SIZE" "$SIZE" "$SIZE" 2>&1 | tee /dev/tty)

        # Extract Kernel time
        RESULT_LINE=$(echo "$OUTPUT" | grep -m1 "$METHOD")

        KERNEL=$(echo "$RESULT_LINE" | awk -F', ' '{print $4}')

        # Check if Kernel time is empty or zero, if so, set to zero
        KERNEL=${KERNEL:-0}

        # Compute GFLOPS/s: (2 * m * n * k) / (Kernel Time * 10^9)
        if [[ "$KERNEL" == "0" || "$KERNEL" == "" ]]; then
            GFLOPS="0"
        else
            GFLOPS=$(echo "scale=6; (2 * $SIZE * $SIZE * $SIZE) / ($KERNEL * 10^9)" | bc)
        fi

(... more ...)
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   173.00 sec.
    Max Memory :                                 125 MB
    Average Memory :                             122.00 MB
    Total Requested Memory :                     65536.00 MB
    Delta Memory :                               65411.00 MB
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                11
    Run time :                                   167 sec.
    Turnaround time :                            149 sec.

The output (if any) is above this job summary.

