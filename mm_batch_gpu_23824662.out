mkn_omp, 1, 100, 0.000438, 4566.21
mkn_omp, 1, 200, 0.003874, 4130.09
mkn_omp, 1, 500, 0.111961, 2232.92
mkn_omp, 1, 1000, 0.922971, 2166.91
mkn_omp, 1, 2000, 8.218674, 1946.78
mkn_omp, 1, 5000, 543.828912, 459.70
mkn_omp, 2, 100, 0.000281, 7117.43
mkn_omp, 2, 200, 0.001979, 8084.89
mkn_omp, 2, 500, 0.056142, 4452.99
mkn_omp, 2, 1000, 0.461868, 4330.24
mkn_omp, 2, 2000, 3.862451, 4142.44
mkn_omp, 2, 5000, 267.975817, 932.92
mkn_omp, 4, 100, 0.000146, 13698.63
mkn_omp, 4, 200, 0.001015, 15763.54
mkn_omp, 4, 500, 0.028138, 8884.78
mkn_omp, 4, 1000, 0.230971, 8659.09
mkn_omp, 4, 2000, 2.114764, 7565.85
User defined signal 2

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 23824662: <mm_batch_gpu> in cluster <dcc> Exited

Job <mm_batch_gpu> was submitted from host <n-62-11-46> by user <s230274> in cluster <dcc> at Wed Jan 22 16:45:06 2025
Job was executed on host(s) <32*n-62-12-88>, in queue <hpcintrogpu>, as user <s230274> in cluster <dcc> at Wed Jan 22 16:45:08 2025
</zhome/97/2/198344> was used as the home directory.
</zhome/97/2/198344/assignment_3/hpc_assignment3> was used as the working directory.
Started at Wed Jan 22 16:45:08 2025
Terminated at Wed Jan 22 17:00:22 2025
Results reported at Wed Jan 22 17:00:22 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# 02614 - High-Performance Computing, January 2024
# Batch script to run matmult on a dedicated GPU server in the hpcintrogpu queue

#BSUB -J mm_batch_gpu
#BSUB -o mm_batch_gpu_%J.out
#BSUB -q hpcintrogpu
#BSUB -n 32                      
#BSUB -R "rusage[mem=2048]"
#BSUB -W 15
#BSUB -R "span[hosts=1]"
#BSUB -gpu "num=1:mode=exclusive_process"

# Define the executable name
EXECUTABLE=matmult_c.nvc++

# Define problem sizes
SIZES="100 200 500 1000 2000 5000"

# Define computation methods
TYPES="mkn_omp lib"

# Define number of threads
THREADS="1 2 4 8 16"

# Enable (1) / Disable (0) result checking
export MATMULT_COMPARE=0

# Load CUDA libraries
module load nvhpc/24.11

# Output file for results
RESULTS_FILE="performance_results.txt"

# Clear the results file before writing new data
echo "Method, Threads, Size, Execution Time (s), MFLOPS" > $RESULTS_FILE

# Run the performance tests
for T in $TYPES; do
    for N in $THREADS; do
        export OMP_NUM_THREADS=$N  # Set number of OpenMP threads
        for S in $SIZES; do
            # Run the executable and capture the execution time
            OUTPUT=$(./$EXECUTABLE $T $S $S $S)
            EXEC_TIME=$(echo "$OUTPUT" | grep "Execution time" | sed 's/[^0-9.]//g' | tail -n1)  # Extract time from output

            # Compute MFLOPS (Floating-Point Operations per Second)
            MFLOPS=$(echo "scale=2; (2 * $S * $S * $S) / ($EXEC_TIME * 1000000)" | bc)

            # Print and save results

(... more ...)
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   1276.00 sec.
    Max Memory :                                 110 MB
    Average Memory :                             67.00 MB
    Total Requested Memory :                     65536.00 MB
    Delta Memory :                               65426.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                12
    Run time :                                   916 sec.
    Turnaround time :                            916 sec.

The output (if any) is above this job summary.

