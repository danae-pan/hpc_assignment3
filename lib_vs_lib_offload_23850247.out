Testing lib with matrix size 100...
Saved: lib, 100, 0.000082, 24.390243
Testing lib_offload with matrix size 100...
Saved: lib_offload, 100, 0.000098, 20.408163
Speedup for size 100: .836734
Testing lib with matrix size 500...
Saved: lib, 500, 0.006410, 39.001560
Testing lib_offload with matrix size 500...
Saved: lib_offload, 500, 0.000784, 318.877551
Speedup for size 500: 8.176020
Testing lib with matrix size 1000...
Saved: lib, 1000, 0.049398, 40.487469
Testing lib_offload with matrix size 1000...
Saved: lib_offload, 1000, 0.001064, 1879.699248
Speedup for size 1000: 46.426691
Testing lib with matrix size 2000...
Saved: lib, 2000, 0.385114, 41.546139
Testing lib_offload with matrix size 2000...
Saved: lib_offload, 2000, 0.003818, 4190.675746
Speedup for size 2000: 100.867993
Testing lib with matrix size 5000...
Saved: lib, 5000, 5.902635, 42.353965
Testing lib_offload with matrix size 5000...
Saved: lib_offload, 5000, 0.007763, 32204.044828
Speedup for size 5000: 760.354888
Testing lib with matrix size 10000...
Saved: lib, 10000, 47.114880, 42.449434
Testing lib_offload with matrix size 10000...
Saved: lib_offload, 10000, 0.029189, 68518.962622
Speedup for size 10000: 1614.131350
Results saved to lib_vs_lib_offload_results.csv

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 23850247: <lib_vs_lib_offload> in cluster <dcc> Done

Job <lib_vs_lib_offload> was submitted from host <n-62-12-81> by user <s182821> in cluster <dcc> at Thu Jan 23 19:08:26 2025
Job was executed on host(s) <32*n-62-12-88>, in queue <hpcintrogpu>, as user <s182821> in cluster <dcc> at Thu Jan 23 19:08:27 2025
</zhome/4c/5/135583> was used as the home directory.
</zhome/4c/5/135583/assignment_3/repo/hpc_assignment3> was used as the working directory.
Started at Thu Jan 23 19:08:27 2025
Terminated at Thu Jan 23 19:12:10 2025
Results reported at Thu Jan 23 19:12:10 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/bash
# Batch script to compare CPU (lib) and GPU (lib_offload) DGEMM performance

#BSUB -J lib_vs_lib_offload
#BSUB -o lib_vs_lib_offload_%J.out
#BSUB -q hpcintrogpu
#BSUB -n 32
#BSUB -R "rusage[mem=2048]"
#BSUB -W 15
#BSUB -R "span[hosts=1]"
#BSUB -gpu "num=1:mode=exclusive_process"

# Define methods to test
METHODS="lib lib_offload"

# Define matrix sizes to experiment with
MATRIX_SIZES="100 500 1000 2000 5000 10000"

# Output file
RESULTS_FILE="lib_vs_lib_offload_results.csv"

# Clear old results
echo "Method, Matrix Size, Execution Time (s), GFLOPS/s, Speedup (CPU/GPU)" > $RESULTS_FILE

# Load necessary modules (adjust if required)
module load nvhpc/24.11

# Run tests for lib and lib_offload with different matrix sizes
for SIZE in $MATRIX_SIZES; do
    CPU_TIME=0  # Store CPU execution time for speedup calculation
    GPU_TIME=0  # Store GPU execution time for speedup calculation

    for METHOD in $METHODS; do
        echo "Testing $METHOD with matrix size $SIZE..."

        # Run executable and capture output
        OUTPUT=$(./matmult_c.nvc++ "$METHOD" "$SIZE" "$SIZE" "$SIZE")

        # Extract execution time
        RESULT_LINE=$(echo "$OUTPUT" | grep -m1 "$METHOD")
        EXEC_TIME=$(echo "$RESULT_LINE" | awk -F', ' '{print $3}')

        # Ensure non-empty execution time
        EXEC_TIME=${EXEC_TIME:-0}

        # Compute GFLOPS/s: (2 * m * n * k) / (Execution Time * 10^9)
        if [[ "$EXEC_TIME" == "0" || "$EXEC_TIME" == "" ]]; then
            GFLOPS="0"
        else
            GFLOPS=$(echo "scale=6; (2 * $SIZE * $SIZE * $SIZE) / ($EXEC_TIME * 10^9)" | bc)

(... more ...)
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   236.00 sec.
    Max Memory :                                 129 MB
    Average Memory :                             123.25 MB
    Total Requested Memory :                     65536.00 MB
    Delta Memory :                               65407.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                9
    Run time :                                   290 sec.
    Turnaround time :                            224 sec.

The output (if any) is above this job summary.

